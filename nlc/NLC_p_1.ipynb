{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3T1TrfAFlgnY4Af0iaQVp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumyuck/ML-learning/blob/main/nlc/NLC_p_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqFJc3RUbATv",
        "outputId": "84ea0a90-92ef-4a03-b7db-27f11c847f2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found email addresses: ['support@example.com']\n",
            "Found phone number: 123-456-7890\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Example text\n",
        "text = \"Contact us at support@example.com or call us at 123-456-7890.\"\n",
        "\n",
        "# Pattern matching: Find all email addresses in the text\n",
        "email_pattern = r'\\S+@\\S+'\n",
        "emails = re.findall(email_pattern, text)\n",
        "print(\"Found email addresses:\", emails)\n",
        "\n",
        "# Text extraction: Extract the phone number\n",
        "phone_pattern = r'\\d{3}-\\d{3}-\\d{4}'\n",
        "phone_number = re.search(phone_pattern, text)\n",
        "if phone_number:\n",
        "  print(\"Found phone number:\", phone_number.group(0))\n",
        "else:\n",
        "  print(\"Phone number not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download necessary NLTK data (if you haven't already)\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "text = \"NLTK is a powerful library for natural language processing. It helps with tokenization, stemming, and lemmatization.\"\n",
        "\n",
        "# Tokenization\n",
        "words = word_tokenize(text)\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "print(\"Word tokens:\", words)\n",
        "print(\"Sentence tokens:\", sentences)\n",
        "\n",
        "# Stemming\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(\"Stemmed words:\", stemmed_words)\n",
        "\n",
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "print(\"Lemmatized words:\", lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPuRX15CdgrF",
        "outputId": "8797b254-e05f-4ba7-ff4a-1818570721ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word tokens: ['NLTK', 'is', 'a', 'powerful', 'library', 'for', 'natural', 'language', 'processing', '.', 'It', 'helps', 'with', 'tokenization', ',', 'stemming', ',', 'and', 'lemmatization', '.']\n",
            "Sentence tokens: ['NLTK is a powerful library for natural language processing.', 'It helps with tokenization, stemming, and lemmatization.']\n",
            "Stemmed words: ['nltk', 'is', 'a', 'power', 'librari', 'for', 'natur', 'languag', 'process', '.', 'it', 'help', 'with', 'token', ',', 'stem', ',', 'and', 'lemmat', '.']\n",
            "Lemmatized words: ['NLTK', 'is', 'a', 'powerful', 'library', 'for', 'natural', 'language', 'processing', '.', 'It', 'help', 'with', 'tokenization', ',', 'stemming', ',', 'and', 'lemmatization', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"Apple is looking at buying U.K. startup for $1 billion.\"\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "# Named Entity Recognition (NER)\n",
        "print(\"Named Entities:\")\n",
        "for ent in doc.ents:\n",
        "    print(f\"{ent.text} ({ent.label_})\")\n",
        "\n",
        "# Dependency Parsing\n",
        "print(\"\\nDependency Parsing:\")\n",
        "for token in doc:\n",
        "    print(f\"{token.text} ({token.pos_}) - {token.dep_} -> {token.head.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHD8xqvpePW7",
        "outputId": "475413f7-f37e-4b3f-9669-de48e8b79ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entities:\n",
            "Apple (ORG)\n",
            "U.K. (GPE)\n",
            "$1 billion (MONEY)\n",
            "\n",
            "Dependency Parsing:\n",
            "Apple (PROPN) - nsubj -> looking\n",
            "is (AUX) - aux -> looking\n",
            "looking (VERB) - ROOT -> looking\n",
            "at (ADP) - prep -> looking\n",
            "buying (VERB) - pcomp -> at\n",
            "U.K. (PROPN) - nsubj -> startup\n",
            "startup (VERB) - ccomp -> buying\n",
            "for (ADP) - prep -> startup\n",
            "$ (SYM) - quantmod -> billion\n",
            "1 (NUM) - compound -> billion\n",
            "billion (NUM) - pobj -> for\n",
            ". (PUNCT) - punct -> looking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "from googletrans import Translator\n",
        "\n",
        "text = \"TextBlob is a great library for sentiment analysis and translation.\"\n",
        "\n",
        "# Sentiment Analysis\n",
        "blob = TextBlob(text)\n",
        "sentiment = blob.sentiment\n",
        "print(f\"Sentiment of the text: {sentiment}\")\n",
        "\n",
        "# Translation\n",
        "translator = Translator()\n",
        "translated_text = translator.translate(text_to_translate, dest='es')\n",
        "print(f\"Translated text (Spanish): {translated_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBPn1k24eobX",
        "outputId": "aab6bfa4-b98c-442c-de00-ed5200348f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment of the text: Sentiment(polarity=0.8, subjectivity=0.75)\n",
            "Translated text (Spanish): Translated(src=en, dest=es, text=¿Hola, cómo estás?, pronunciation=None, extra_data=\"{'confiden...\")\n"
          ]
        }
      ]
    }
  ]
}